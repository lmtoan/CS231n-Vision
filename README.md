# CS231n-Vision
All assignments for Stanford CS231n:Convolutional Neural Networks for Visual Recognition class
http://cs231n.stanford.edu/syllabus.html

Assignment 1 (Completed in March 2017): 
- Q1: k-Nearest Neighbor classifier (knn_Toan.py)
- Q2: Training a Support Vector Machine (svm_Toan.py)
- Q3: Implement a Softmax classifier (softmax_Toan.py)
- Q4: Two-Layer Neural Network (two_layer_net.py)
- Q5: Higher Level Representations: Image Features (features_Toan.py)

Assignment 2 (Implemented on Google Cloud. Completed in April 2017):
- Q1: Fully-connected Neural Network (FullyConnectedNets_Toan.ipynb)
- Q2: Batch Normalization (BatchNormalization_Toan.ipynb)
- Q3: Dropout (Dropout_Toan.ipynb)
- Q4: Convolutional Networks (ConvolutionalNetworks_Toan.ipynb)
- Q5: TensorFlow on CIFAR-10 (Tensorflow_Toan.ipynb). Best performance using a simplified ResNet: **Accuracy of 80.1%**
- Q5b: PyTorch on CIFAR-10 (PyTorch_Toan.ipynb). Experiment classfication with PyTorch. Attempted transfer-learning but needed a 224x224 image set

Assignment 3 (Implemented on med2lab.com GPU server. In progress as of May 2017):
- Q1: Image Captioning with Vanilla RNNs on MS-COCO data (RNN_Captioning_Toan.ipynb)
- Q2: Image Captioning with Long-Short Term Memory (LSTM) RNNs on MS-COCO data (LSTM_Captioning_Toan.ipynb)
- Q3: **(Completed in PyTorch)** Network Visualization: Saliency maps, Class Visualization, and Fooling Images. *Introduce the pretrained SqueezeNet model, compute gradients with respect to images, and use them to produce saliency maps and fooling images* (NetworkVisualization-PyTorch_Toan.ipynb)
- Q4: **(Completed in PyTorch)** Style Transfer. *Learn how to create images with the content of one image but the style of another*
- Q5: **(Completed in PyTorch)** Generative Adversarial Networks. *Learn how to generate images that match a training dataset, and use these models to improve classifier performance when training on a large amount of unlabeled data and a small amount of labeled data*

